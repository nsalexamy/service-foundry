<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Apache Airflow - How to use SparkKubernetesOperator</title>
    <!-- rouge source highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css">
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/service-foundry/pages/assets/css/main.css">

    <!-- Highlight.js script -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>
</head>
<body class="">

<!-- Header -->
<header>
<!--    <div class="logo text-xl font-semibold">Service Foundry</div>-->
    <a href="/service-foundry/pages/index.html" class="text-2xl font-semibold hover:text-teal-400">
    Service Foundry
</a>
    <nav>
    
        
        <a href="/service-foundry/pages/getting-started/" class="">Getting Started</a>
    
        
        <a href="/service-foundry/pages/products/" class="">Products</a>
    
        
        <a href="/service-foundry/pages/documents/" class="active">Docs</a>
    
        
        <a href="/service-foundry/pages/github/" class="">GitHub</a>
    
        
        <a href="/service-foundry/pages/developers/" class="">Developers</a>
    
        
        <a href="/service-foundry/pages/demo/" class="">Demo</a>
    
</nav>
</header>


    <!-- Sub-navigation for Foundries -->
    <div class="subnav">

    
    <a href="/service-foundry/pages/documents/service-foundry/" class="">Service Foundry</a>

    
    <a href="/service-foundry/pages/documents/blog/" class="">Blog</a>

    
    <a href="/service-foundry/pages/documents/infra-foundry/" class="">Infra</a>

    
    <a href="/service-foundry/pages/documents/sso-foundry/" class="">SSO</a>

    
    <a href="/service-foundry/pages/documents/o11y-foundry/" class="">Observability</a>

    
    <a href="/service-foundry/pages/documents/backend-foundry/" class="">Backend</a>

    
    <a href="/service-foundry/pages/documents/bigdata-foundry/" class="active">Big Data</a>

<!--    <a href="/service-foundry/pages/documents/infra-foundry/index-backup.html" class="text-gray-300 hover:text-white">Infra</a>-->
<!--    <a href="/service-foundry/pages/documents/sso-foundry/index-backup.html" class="text-gray-300 hover:text-white">SSO</a>-->
<!--    <a href="/service-foundry/pages/documents/o11y-foundry/index-backup.html" class="text-gray-300 hover:text-white">Observability</a>-->
<!--    <a href="/service-foundry/pages/documents/backend-foundry/index-backup.html" class="text-gray-300 hover:text-white">Backend</a>-->
<!--    <a href="/service-foundry/pages/documents/bigdata-foundry/index-backup.html" class="text-gray-300 hover:text-white">Big Data</a>-->
</div>





<!-- Breadcrumb -->

    <nav class="breadcrumb-wrapper">
    <ol class="breadcrumb">
        
        <li>
            
            <a href="/service-foundry/pages/">Home</a>
            
            
            <span class="separator">/</span>
            
        </li>
        
        <li>
            
            <a href="/service-foundry/pages/documents/">Docs</a>
            
            
            <span class="separator">/</span>
            
        </li>
        
        <li>
            
            <a href="/service-foundry/pages/documents/bigdata-foundry/">BigData Foundry</a>
            
            
        </li>
        
    </ol>
</nav>





<!-- Main Layout -->
<div class="container">


    <nav id="toc-container" class="toc-nav"></nav>


    <main id="main-content">
        
        <div class="author-box">
            Young Gyu Kim
            &lt;<a href="mailto:credemol@gmail.com" style="color: #0d9488; text-decoration: none;">credemol@gmail.com</a>&gt;
        </div>
        

        <!-- Title -->
        
        <h1 class="page-title">
            Apache Airflow - How to use SparkKubernetesOperator
        </h1>
        

        <div class="asciidoc">
            <div id="toc" class="toc">
<div id="toctitle">On this page</div>
<ul class="sectlevel1">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#what-is-spark-operator">What is Spark Operator?</a></li>
<li><a href="#installation">Installation</a>
<ul class="sectlevel2">
<li><a href="#add-the-spark-operator-helm-repository">Add the Spark Operator Helm repository</a></li>
<li><a href="#custom-values-yaml">custom-values.yaml</a></li>
<li><a href="#install-the-spark-operator">Install the Spark Operator</a></li>
</ul>
</li>
<li><a href="#uninstall-the-spark-operator">Uninstall the Spark Operator</a></li>
<li><a href="#create-an-example-application">Create an example application</a>
<ul class="sectlevel2">
<li><a href="#verify-the-spark-application">Verify the Spark application</a></li>
</ul>
</li>
<li><a href="#upgrade-the-spark-operator">Upgrade the Spark Operator</a></li>
<li><a href="#working-with-airflow-3-0-and-sparkkubernetesoperator">Working with Airflow 3.0 and SparkKubernetesOperator</a>
<ul class="sectlevel2">
<li><a href="#extends-git-repository-used-in-airflow-for-dags">Extends Git Repository used in Airflow for DAGs</a></li>
<li><a href="#spark-py-example-py">spark-py-example.py</a></li>
<li><a href="#spark-appsspark-pi-yaml">spark-apps/spark-pi.yaml</a></li>
</ul>
</li>
<li><a href="#rbac-for-sparkkubernetesoperator">RBAC for SparkKubernetesOperator</a></li>
<li><a href="#the-result-of-executing-the-dag">The result of executing the DAG</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</div>
<div id="preamble">
<div class="sectionbody">
<div class="imageblock img-wide">
<div class="content">
<img src="images/intro.png" alt="intro">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction">Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this document, we will explore the Spark Operator, a powerful tool for managing Apache Spark applications on Kubernetes. We will cover the installation process, configuration options, and how to create and manage Spark applications using the Spark Operator.</p>
</div>
<div class="paragraph">
<p>Additionally, we will discuss how to integrate the Spark Operator with Apache Airflow 3.0 using the <strong>SparkKubernetesOperator</strong> to orchestrate Spark jobs.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="what-is-spark-operator">What is Spark Operator?</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Apache Spark</strong> is a powerful open-source distributed computing system that provides an easy-to-use interface for processing large datasets.</p>
</div>
<div class="paragraph">
<p>The <strong>Spark Operator</strong> automates the process of deploying Spark applications, managing their lifecycle, and monitoring their status. It provides a declarative way to define Spark applications using Kubernetes Custom Resource Definitions (CRDs), allowing users to easily create, update, and delete Spark applications using standard Kubernetes tools.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="installation">Installation</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="add-the-spark-operator-helm-repository">Add the Spark Operator Helm repository</h3>
<div class="paragraph">
<p>We are going to use 'spark-operator' provided by Kubeflow. First, check you have added the old version of spark-operator repository provided by Google. Then remove it.</p>
</div>
<div class="paragraph">
<p>Now, add the new Helm repository provided by Kubeflow.</p>
</div>
<div class="listingblock">
<div class="title">add new Helm repository</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>helm repo add spark-operator https://kubeflow.github.io/spark-operator

<span class="nv">$ </span>helm repo update spark-operator

<span class="nv">$ </span>helm repo list | <span class="nb">grep </span>spark-operator

spark-operator          https://kubeflow.github.io/spark-operator</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">pull the spark-operator chart</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>helm pull spark-operator/spark-operator

<span class="c"># as of October 2025, the latest version is 2.3.0</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">download the values.yaml file.</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>helm show values <span class="nt">--version</span> 2.3.0 spark-operator/spark-operator <span class="o">&gt;</span> values-2.3.0.yaml</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="custom-values-yaml">custom-values.yaml</h3>
<div class="paragraph">
<p>You can customize the values.yaml file to fit your needs. Here is an example of custom-values.yaml.</p>
</div>
<div class="listingblock">
<div class="title">custom-values.yaml</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">spark</span><span class="pi">:</span>
  <span class="c1"># -- List of namespaces where to run spark jobs.</span>
  <span class="na">jobNamespaces</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">spark-jobs</span>
  <span class="pi">-</span> <span class="s">airflow</span>
  <span class="pi">-</span> <span class="s">default</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>For spark.jobNamespace, you can specify the namespace where the Spark applications will be created.</p>
</div>
</div>
<div class="sect2">
<h3 id="install-the-spark-operator">Install the Spark Operator</h3>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>helm <span class="nb">install </span>spark-operator spark-operator/spark-operator <span class="nt">--namespace</span> spark-operator <span class="nt">--create-namespace</span> <span class="nt">-f</span> custom-values.yaml</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="uninstall-the-spark-operator">Uninstall the Spark Operator</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>helm uninstall spark-operator <span class="nt">-n</span> spark-operator</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="create-an-example-application">Create an example application</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Spark-Operator examples can be found in the examples directory of the Spark-Operator repository.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/kubeflow/spark-operator/tree/master/examples" class="bare">https://github.com/kubeflow/spark-operator/tree/master/examples</a></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">examples/spark-pi.yaml</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="c1">#</span>
<span class="c1"># Copyright 2017 Google LLC</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">sparkoperator.k8s.io/v1beta2</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">SparkApplication</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-pi</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">Scala</span>
  <span class="na">mode</span><span class="pi">:</span> <span class="s">cluster</span>
  <span class="na">image</span><span class="pi">:</span> <span class="s">docker.io/library/spark:4.0.0</span>
  <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
  <span class="na">mainClass</span><span class="pi">:</span> <span class="s">org.apache.spark.examples.SparkPi</span>
  <span class="na">mainApplicationFile</span><span class="pi">:</span> <span class="s">local:///opt/spark/examples/jars/spark-examples.jar</span>
  <span class="na">arguments</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">5000"</span>
  <span class="na">sparkVersion</span><span class="pi">:</span> <span class="s">4.0.0</span>
  <span class="na">driver</span><span class="pi">:</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s">4.0.0</span>
    <span class="na">cores</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">memory</span><span class="pi">:</span> <span class="s">512m</span>
    <span class="na">serviceAccount</span><span class="pi">:</span> <span class="s">spark-operator-spark</span>
    <span class="na">securityContext</span><span class="pi">:</span>
      <span class="na">capabilities</span><span class="pi">:</span>
        <span class="na">drop</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">ALL</span>
      <span class="na">runAsGroup</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsUser</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsNonRoot</span><span class="pi">:</span> <span class="kc">true</span>
      <span class="na">allowPrivilegeEscalation</span><span class="pi">:</span> <span class="kc">false</span>
      <span class="na">seccompProfile</span><span class="pi">:</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">RuntimeDefault</span>
  <span class="na">executor</span><span class="pi">:</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s">4.0.0</span>
    <span class="na">instances</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">cores</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">memory</span><span class="pi">:</span> <span class="s">512m</span>
    <span class="na">securityContext</span><span class="pi">:</span>
      <span class="na">capabilities</span><span class="pi">:</span>
        <span class="na">drop</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">ALL</span>
      <span class="na">runAsGroup</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsUser</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsNonRoot</span><span class="pi">:</span> <span class="kc">true</span>
      <span class="na">allowPrivilegeEscalation</span><span class="pi">:</span> <span class="kc">false</span>
      <span class="na">seccompProfile</span><span class="pi">:</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">RuntimeDefault</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>I just changed the namespace to 'spark-jobs' in the example file.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c">#$ kubectl get namespace spark-jobs || kubectl create namespace spark-jobs</span>

<span class="c"># Create an example Spark application in the spark-jobs namespace</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> examples/spark-pi.yaml</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="verify-the-spark-application">Verify the Spark application</h3>
<div class="paragraph">
<p>To verify the Spark application, you can check the logs of the driver pod.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>kubectl get pods
<span class="nv">$ </span>kubectl logs <span class="nt">-f</span> spark-pi-driver</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="upgrade-the-spark-operator">Upgrade the Spark Operator</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>helm upgrade spark-operator spark-operator/spark-operator <span class="nt">--namespace</span> spark-operator <span class="nt">-f</span> custom-values.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="working-with-airflow-3-0-and-sparkkubernetesoperator">Working with Airflow 3.0 and SparkKubernetesOperator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>For more details about how to install Apache Airflow 3 on Kubernetes, please refer to the following document:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://nsalexamy.github.io/service-foundry/pages/documents/bigdata-foundry/airflow-with-service-foundry/">Installing Apache Airflow 3 on Kubernetes</a></p>
</li>
<li>
<p><a href="https://youtu.be/JzIXVxYS0uQ">YouTube Video - Installing Apache Airflow 3 on Kubernetes</a></p>
</li>
<li>
<p><a href="https://youtu.be/OS5t1Ubqp1k">YouTube Video - Installing Apache Airflow 3 on Kubernetes with GitOps using Service Foundry</a></p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="extends-git-repository-used-in-airflow-for-dags">Extends Git Repository used in Airflow for DAGs</h3>
<div class="paragraph">
<p>A directory named <strong>spark-apps/</strong> needs to be created under the <strong>dags/</strong> directory in the Airflow Git repository to store the Spark application YAML files.</p>
</div>
<div class="listingblock">
<div class="title">file structure in Airflow Git Repository</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>tree dags <span class="nt">--dirsfirst</span>
dags
├── spark-apps
│   └── spark-pi.yaml
├── hello_world_dag.py
└── spark-py-example.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>File descriptions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>spark-py-example.py: An example DAG that uses SparkKubernetesOperator to submit a Spark application.</p>
</li>
<li>
<p>spark-apps/spark-pi.yaml: The Spark application YAML file used in the DAG.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The application directory which is <strong>spark-apps/</strong> must be located under the <strong>dags/</strong> directory in the Airflow Git repository.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="spark-py-example-py">spark-py-example.py</h3>
<div class="paragraph">
<p>This is an example DAG that uses SparkKubernetesOperator to submit a Spark application to the Kubernetes cluster.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span><span class="p">,</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="n">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="n">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">owner</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">airflow</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">depends_on_past</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">:</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span> <span class="o">-</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">email</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">airflow@example.com</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">email_on_failure</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">email_on_retry</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">max_active_runs</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">retries</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">startBatch</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">##### startBatch #####</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">done</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">##### done #####</span><span class="sh">'</span><span class="p">)</span>

<span class="k">with</span> <span class="nc">DAG</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="sh">'</span><span class="s">spark_pi</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span> <span class="o">-</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
    <span class="n">schedule</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">example</span><span class="sh">'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    <span class="n">spark_pi_task</span> <span class="o">=</span> <span class="nc">SparkKubernetesOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sh">'</span><span class="s">spark_example</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">namespace</span><span class="o">=</span><span class="sh">'</span><span class="s">airflow</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">application_file</span><span class="o">=</span><span class="sh">'</span><span class="s">spark-apps/spark-pi.yaml</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">kubernetes_conn_id</span><span class="o">=</span><span class="sh">'</span><span class="s">kubernetes_default</span><span class="sh">'</span><span class="p">,</span>

    <span class="p">)</span>

    <span class="n">start_batch_task</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sh">'</span><span class="s">startBatch</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">startBatch</span>
    <span class="p">)</span>
    <span class="n">done_task</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sh">'</span><span class="s">done</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">done</span>
    <span class="p">)</span>


    <span class="n">start_batch_task</span> <span class="o">&gt;&gt;</span> <span class="n">spark_pi_task</span> <span class="o">&gt;&gt;</span> <span class="n">done_task</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="spark-appsspark-pi-yaml">spark-apps/spark-pi.yaml</h3>
<div class="paragraph">
<p>This is an example Spark application provided by Spark Operator. Make sure the namespace matches the one used in the Airflow DAG.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">sparkoperator.k8s.io/v1beta2</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">SparkApplication</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-pi</span>
  <span class="c1"># &lt;1&gt; Make sure the namespace matches the one used in the Airflow DAG</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">airflow</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">Scala</span>
  <span class="na">mode</span><span class="pi">:</span> <span class="s">cluster</span>
  <span class="na">image</span><span class="pi">:</span> <span class="s">docker.io/library/spark:4.0.0</span>
  <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
  <span class="na">mainClass</span><span class="pi">:</span> <span class="s">org.apache.spark.examples.SparkPi</span>
  <span class="na">mainApplicationFile</span><span class="pi">:</span> <span class="s">local:///opt/spark/examples/jars/spark-examples.jar</span>
  <span class="na">arguments</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">5000"</span>
  <span class="na">sparkVersion</span><span class="pi">:</span> <span class="s">4.0.0</span>
  <span class="na">driver</span><span class="pi">:</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s">4.0.0</span>
    <span class="na">cores</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">memory</span><span class="pi">:</span> <span class="s">512m</span>
    <span class="na">serviceAccount</span><span class="pi">:</span> <span class="s">spark-operator-spark</span>
    <span class="na">securityContext</span><span class="pi">:</span>
      <span class="na">capabilities</span><span class="pi">:</span>
        <span class="na">drop</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">ALL</span>
      <span class="na">runAsGroup</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsUser</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsNonRoot</span><span class="pi">:</span> <span class="kc">true</span>
      <span class="na">allowPrivilegeEscalation</span><span class="pi">:</span> <span class="kc">false</span>
      <span class="na">seccompProfile</span><span class="pi">:</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">RuntimeDefault</span>
  <span class="na">executor</span><span class="pi">:</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s">4.0.0</span>
    <span class="na">instances</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">cores</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">memory</span><span class="pi">:</span> <span class="s">512m</span>
    <span class="na">securityContext</span><span class="pi">:</span>
      <span class="na">capabilities</span><span class="pi">:</span>
        <span class="na">drop</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">ALL</span>
      <span class="na">runAsGroup</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsUser</span><span class="pi">:</span> <span class="m">185</span>
      <span class="na">runAsNonRoot</span><span class="pi">:</span> <span class="kc">true</span>
      <span class="na">allowPrivilegeEscalation</span><span class="pi">:</span> <span class="kc">false</span>
      <span class="na">seccompProfile</span><span class="pi">:</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">RuntimeDefault</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="rbac-for-sparkkubernetesoperator">RBAC for SparkKubernetesOperator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The airflow-worker service account needs to have permissions to create SparkApplication resources in the target namespace.</p>
</div>
<div class="listingblock">
<div class="title">spark-rbac.yaml</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="c1"># spark-rbac.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Role</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-application-role</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">airflow</span>
<span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">sparkoperator.k8s.io"</span><span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">sparkapplications"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">sparkapplications/status"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">sparkapplications/finalizers"</span>
    <span class="na">verbs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">create</span>
      <span class="pi">-</span> <span class="s">get</span>
      <span class="pi">-</span> <span class="s">list</span>
      <span class="pi">-</span> <span class="s">watch</span>
      <span class="pi">-</span> <span class="s">update</span>
      <span class="pi">-</span> <span class="s">patch</span>
      <span class="pi">-</span> <span class="s">delete</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">RoleBinding</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-application-rolebinding</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">airflow</span>
<span class="na">subjects</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">airflow-worker</span>
    <span class="na">namespace</span><span class="pi">:</span> <span class="s">airflow</span>
<span class="na">roleRef</span><span class="pi">:</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Role</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-application-role</span>
  <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Apply the RBAC configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> spark-rbac.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="the-result-of-executing-the-dag">The result of executing the DAG</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When you trigger the <strong>spark_pi</strong> DAG in Airflow, it will create a SparkApplication resource in the Kubernetes cluster. You can monitor the status of the Spark application using kubectl.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>kubectl get sparkapplications <span class="nt">-n</span> airflow</code></pre>
</div>
</div>
<div class="paragraph">
<p>And you can see the graphical representation of the DAG in the Airflow web UI.</p>
</div>
<div class="imageblock img-wide">
<div class="content">
<img src="images/airflow-dag-execution.png" alt="airflow dag execution">
</div>
<div class="title">Figure 1. Airflow DAG Execution</div>
</div>
<div class="paragraph">
<p>The second task is the SparkKubernetesOperator task that submits the Spark application to the Kubernetes cluster.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="conclusion">Conclusion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This document provided an overview of how to install and use the Spark Operator on Kubernetes, as well as how to integrate it with Apache Airflow 3.0 using the SparkKubernetesOperator. By following the steps outlined in this document, you can easily deploy and manage Spark applications on your Kubernetes cluster using Airflow.</p>
</div>
</div>
</div>
        </div>
    </main>
</div>




<script>
    const toc = document.getElementById('toc');
    const container = document.getElementById('toc-container');
    if (toc && container) {
        container.appendChild(toc);
    }
</script>


<!--<button onclick="toggleTheme()" style="position: fixed; bottom: 1rem; right: 1rem; padding: 0.5rem 1rem; background-color: var(&#45;&#45;link); color: white; border: none; border-radius: 0.375rem; cursor: pointer;">-->
<!--    Toggle Theme-->
<!--</button>-->

<!--<script>-->
<!--    function toggleTheme() {-->
<!--        const html = document.documentElement;-->
<!--        const isDark = html.getAttribute("data-theme") === "dark";-->
<!--        html.setAttribute("data-theme", isDark ? "light" : "dark");-->
<!--        localStorage.setItem("theme", isDark ? "light" : "dark");-->
<!--    }-->

<!--    document.addEventListener("DOMContentLoaded", () => {-->
<!--        const savedTheme = localStorage.getItem("theme") || "light";-->
<!--        document.documentElement.setAttribute("data-theme", savedTheme);-->
<!--    });-->
<!--</script>-->

<!-- Footer -->
<footer class="bg-gray-900 text-white text-sm py-6 text-center">
    © 2025 Service Foundry. All rights reserved.
</footer>
</body>
</html>